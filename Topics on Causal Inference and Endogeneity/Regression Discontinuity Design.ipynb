{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "We know that, to do treatment effect, we need make convincing assumption that inviduals chooses gets into the treatment based on some observable variables. A speical case is that, invidiuals get treatment when $x$ is larger than a threhold value $c$. A big problem with this situation is that common support assumption is violated: there is no overlapping $x$ in treatment group and control group. \n",
    "\n",
    "# Sharp RDD\n",
    "A strategy is focusing on the local area around $c$. We can think of that for people with $x$ very close to $c$, they are actually very close to each other; whether they get treatment or not is nearly random. \n",
    "\n",
    "To be more specific, consider $(c-\\epsilon, c+\\epsilon)$, where $\\epsilon$ is very small.  For those individuals at $(c-\\epsilon, 0)$ and at $(0, c+\\epsilon)$, we can regard them as having identical $x$, and whether they get treatment or not is purely random. \n",
    "\n",
    "Therefore, we can impose the following CIA assumption: <b>given $x=c$, $z$, whether getting treatment or not is random </b>. This allows us to estimate the ATE at $x=c$. Of course, in other values of $x$, the CIA is violated, so we <b>cannot</b> estimate ATE.\n",
    "\n",
    "$$LATE(z)= E(y_1 -  y_0 | D= 1, x= c, z) = E(y_1 |D =1, x= c, z) -  E(y_0 |D =1, x= c, z) $$\n",
    "with the above CIA assumption, s.t. given $x=c$, $z$, we easily have \n",
    "$$LATE(z) = E(y_1 |D =1, x= c, z)-  E(y_0 |D =0, x= c, z) $$ \n",
    "\n",
    "Next we need to estimate $E(y_1 |D =1, x= c, z)$ and $ E(y_0 |D =0, x= c, z)$\n",
    "\n",
    "## Estimation Method\n",
    "### Non-parametric\n",
    "\n",
    "How to estimate $E(y_1 |D =1, x= c, z)$? Only those inviduals with $x<c$ get the treatment, so we can estimate this term using \n",
    "$$\\lim_{x \\rightarrow c^{+}}{E(y|x,z)}$$\n",
    "Similarly, we can estimate  $E(y_0 |D =0, x= c, z)$ using $\\lim_{x \\rightarrow c^{-}}{E(y|x,z)}$.\n",
    "\n",
    "$$LATE(x=c, z) = \\lim_{x \\rightarrow c^{+}}{E(y|x,z)}-\\lim_{x \\rightarrow c^{-}}{E(y|x,z)}$$\n",
    "\n",
    "In which $z$ is other exogeneous covariates. This expression gives the local effect of treatment at $x=c$ and $z$. Of course we can average the $LATE$ over $z$:\n",
    "\n",
    "$$LATE(x=c) \\equiv \\int{ \\lim_{x \\rightarrow c^{+}}{E(y|x,z)}pr(z|x)dz}- \\int{\\lim_{x \\rightarrow c^{-}}{E(y|x,z)} pr(z|x)dz}$$\n",
    "\n",
    "This expression gives more details we need pay attention to. From this expression, $LATE(x=c)$ comes from two part: one is the effect of treatment, the other is difference of z's distribution between $pr(z|x,x \\rightarrow c^{+})$ and $pr(z|x,x \\rightarrow c^{-})$. If these two distributions are different, then we cannot estimate the real effect of the treatment. Therefore, <b>before estimation, confirm that the these two distributions are identical !</b>\n",
    "    \n",
    "### Regression: \n",
    "We can also consider the following regression when $x \\in (c-h, c+h)$:\n",
    "$$y = \\alpha + \\beta (x-c) + \\delta*1\\{x>c\\} + \\gamma *1\\{x>c\\}*(x-c)+ \\theta z+ \\epsilon$$\n",
    "\n",
    "- By estimating $\\delta$ we can get the effect the net effect of treatment on $y$. The $ \\gamma *1\\{x>c\\}*(x-c)$ is to allow for the differnet in slopes on $x<c$ and $x>c$. This term is not necessary, though. \n",
    "- Again, be sure that $z$'s distributions are identical on the two sides of $x=c$ (i.e, check that $z$ is independent of $1\\{x>c\\}$). If not, the estimated $\\delta$ is in general not the net effect of the treatment.\n",
    "- One obvious problem with this regression is that it only use the information of those data at $x \\in (c-h, c+h)$. This is not good. To make use of more data points, we can instead use local linear regression, by estimating: \n",
    "$$\\min_{\\alpha, \\beta, \\delta, \\gamma} {\\sum_{i=1}^{n}K\\left(\\frac{x_i - c}{h}\\right){\\left( y_i - \\alpha - \\beta (x_i -c) -\\delta* 1\\{x_i >c\\} - \\gamma *1\\{x_i >c\\} * (x_i -c) \\right) }^{2} }$$\n",
    "\n",
    "\n",
    "\n",
    "## Remarks\n",
    "\n",
    "- Check This Assumption :<b>Individuals do not know the value $c$ ex-ante, i.e., they cannot adjust their own $x$ ex-ante according to $c$</b>. If, otherwise, individuals knows the $c$ (and also, the benefit of getting treatment) beforehand, they could change their $x$ to affect whether they get treatment or not. In this sense, treatment is no longer random. \n",
    "    - Consider a situation, where we study the effect of whether going to university on subsequent income. Suppose people know that they can get into university if their score is above 500. if I am a hard-working person and I know I can get into the university if my exam score is abot 500, I will work hard to make my score, $x$, be above 500. Since I am a hard-working person, it is also possible that I earn high income. Self-selection problem happens again! Therefore, <b>RDD is good for the situation where $x$ is predetermined (determined before people know the $c$)</b>\n",
    "\n",
    "- So in general, we need to check the distributions of $x$ on both sides near the $c$ and confirm if the distribution is continuous at $x = c$. If not, then randomness is doubtful.\n",
    "\n",
    "- As is stressed above, make sure the other covariates $z$ has the same distribution at the two sides of $x=c$\n",
    "- Although the RDD seems limited in the sense that we can infer the effect of the treatment around the threshold. But it is still useful, since in reality we do encounter similar cases:\n",
    "    - Customer can be prime member when their purchase $x$ is above a threshold value. \n",
    "    - People can enjoy a certain pension benefit when their income $x$ is below a certain level.\n",
    "    - ...\n",
    "    \n",
    "  Of course, before estimation, confirm that individuals' $x$ is predetermined before the treatment is put into effect.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fuzzy RDD\n",
    "Now we consider a case where the threshold $c$ is 'fuzzy', in the sense that there is just of jump of the probability of getting into treatment from $x = c^{-}$ to $x = c^{+}$,i.e., \n",
    "$$a = \\lim_{x \\rightarrow c^{-}}pr(D = 1|x) \\ne \\lim_{x \\rightarrow c^{+}}pr(D = 1|x) = b$$\n",
    "When $\\lim_{x \\rightarrow c^{-}}pr(D = 1|x)=0$ and $\\ne \\lim_{x \\rightarrow c^{+}}pr(D = 1|x)=1$, it turns to Sharp RDD.\n",
    "\n",
    "The key issue here is that, even when $x$ is above $c$, individuals may not get into treatment group: it may reject to get treated due to some (observable/unobservable)factors, which may also affect the outcome. Compared to the sharp RDD, fuzzy RDD is more realistic. \n",
    "\n",
    "Notice that when we deal with some basic treatment effect problems, we always do the following procdure:\n",
    "\n",
    "- (method 1) If the decision of whether get treatment is totally random after conditionin on <b>observable variables $x$</b>, i.e., then we can easisy do our estimation by conditioning x.\n",
    "- (method 2)If the decision of whether get treatment is may depend on some ubservable factors, then we have to \n",
    "    - Use some IV: find a dummy variable $z$ that <b>linearly</b> affects the treatment decision, so that we have \n",
    "    $$ATE = \\frac{E(y|z=1)-E(y|z=0)}{E(D|z=1)-E(D|z=0)}$$\n",
    "    see the chapter 'IV and LATE' for detailed information.\n",
    "    - Use heckman two-step or MLE.\n",
    "   \n",
    "The same procedure can be applied to the RDD. we can use method 1, keeping the CIA; we can also use method 2, finding an IV.\n",
    "\n",
    "## Method 1: Keep CIA\n",
    "$$E(y | x) = E(y_1 | D=1, x) pr(D = 1|x) + E(y_0 | D = 0,x ) pr (D=0 |x)$$\n",
    "$$ = \\left(E(y_1 | D=1, x)- E(y_0 | D = 0,x )\\right)pr(D = 1|x)+ E(y_0 | D = 0,x )$$\n",
    "Let's evaluate this equation at $x \\rightarrow c^{+}$ and  $x \\rightarrow c^{-}$ \n",
    "$$\\lim_{x \\rightarrow c^{+}}{E(y |x )} =  \\left(E(y_1 | D=1, x=c)- E(y_0 | D = 0,x =c )\\right)\\lim_{x \\rightarrow c^{+}}pr(D = 1|x)+ E(y_0 | D = 0,x=c ) $$\n",
    "$$\\lim_{x \\rightarrow c^{-}}{E(y |x )} =  \\left(E(y_1 | D=1, x=c)- E(y_0 | D = 0,x =c )\\right)\\lim_{x \\rightarrow c^{-}}pr(D = 1|x)+ E(y_0 | D = 0,x=c ) $$\n",
    " Recall our CIA assumption that $$E(y_0 | D = 0,x =c ) = E(y_0 | D = 1,x =c ) $$\n",
    "    we immedietely get our LATE estimation.\n",
    "$$E(y_1 - y_0 | D=1, x=c)= \\frac{\\lim_{x \\rightarrow c^{+}}{E(y |x )}-\\lim_{x \\rightarrow c^{-}}{E(y |x )} }{\\lim_{x \\rightarrow c^{+}}pr(D = 1|x)-\\lim_{x \\rightarrow c^{-}}pr(D = 1|x)}$$\n",
    "\n",
    "## Method 2: Use IV\n",
    "What is a proper IV for $D$ around $x=c$? One candidate is $Z= 1\\{ x>c\\}$. First, $Z$ is only determined by $x$, so it is not correlated with unobservable factors influencing $y$. Second, $Z$ is obviously related to $D$. We want to estimate \n",
    "$$LATE = \\frac{ E(y|Z=1, x=c)-E(y|Z=0, x= c)}{E(D|Z=1, x=c)-E(D|Z=0, x=c)}$$\n",
    "in which \n",
    "$$ E(y|Z=1, x=c) = E(y| D=1, Z=1, x=c) pr(D=1|Z=1, x=c) +  E(y| D=0, Z=1, x=c) pr(D=0|Z=1, x=c) = $$\n",
    "$$E(y| D=1, Z=1, x=c)* b +  E(y| D=0, Z=1, x=c) *(1-b)$$\n",
    "in which $E(y| D=1, Z=1, x=c)$ can be replaced by $\\lim_{x\\rightarrow c^{+}}{E(y|D=1, x)}$, $E(y| D=0, Z=1, x=c)$ can be replaced by $\\lim_{x\\rightarrow c^{+}}{E(y|D=0, x)}$.\n",
    "Similarly, we have\n",
    "$$ E(y|Z=0, x=c) = E(y| D=1, Z=0, x=c) pr(D=1|Z=0, x=c) +  E(y| D=0, Z=0, x=c) pr(D=0|Z=0, x=c) = $$\n",
    "$$E(y| D=1, Z=0, x=c)* a +  E(y| D=0, Z=0, x=c) *(1-a)$$\n",
    "in which $E(y| D=1, Z=0, x=c)$ can be replaced by $\\lim_{x\\rightarrow c^{-}}{E(y|D=1, x)}$, $E(y| D=0, Z=0, x=c)$ can be replaced by $\\lim_{x\\rightarrow c^{-}}{E(y|D=0, x)}$.\n",
    "Finally we have\n",
    "$$E(D|Z=1, x=c) = pr(D=1|Z=1, x=c) = b, \\quad E(D|Z=0, x=c) = pr(D=1|Z=0, x=c) = a$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
